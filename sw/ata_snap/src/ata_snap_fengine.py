import casperfpga
import struct
import logging
import numpy as np
import time

def _ip_to_int(ip):
    """
    convert an IP string (eg '10.11.10.1') to a 32-bit binary
    string, suitable for writing to an FPGA register.
    """
    octets = list(map(int, ip.split('.')))
    ip_int = (octets[0] << 24) + (octets[1] << 16) + (octets[2] << 8) + octets[3]
    return ip_int

def _int_to_ip(ip):
    """
    convert an IP integer (eg 0x0a0a0a01) to an
    IP string (eg '10.10.10.1')
    """
    sl = [] # list of parts to be joined with dots
    for i in range(4):
        sl += ["%d" % ((ip >> (8*(3-i))) & 0xff)]
    return '.'.join(sl)

def silence_tftpy():
    """
    Turn tftpy's logging filter up to logging.CRITICAL,
    to prevent warnings about tftpy transaction retries.
    """
    logs = [
        'tftpy.TftpClient',
        'tftpy.TftpContext',
        'tftpy.TftpPacketFactory',
        'tftpy.TftpPacketTypes',
        'tftpy.TftpServer',
        'tftpy.TftpStates',
        ]
    for log in logs:
        l = logging.getLogger(log)
        l.setLevel(logging.CRITICAL)

MAX_SAMPLE_DELAY = 16384 - 1

class AtaSnapFengine(object):
    """
    This is a class which implements methods for programming
    and communicating with a SNAP board running the ATA F-Engine
    firmware.

    :param host: Hostname of SNAP board associated with this instance.
    :type host: str
    :param feng_id: Antenna ID of the antenna connected to this SNAP.
        This value is used in the output headers of data packets.
    :type feng_id: int
    :param transport: The type of connection the SNAP supports. Should be either
        casperfpga.TapcpTransport (if communicating over 10GbE) or
        casperfpga.KatcpTransport (if communicating via a Raspberry Pi)
    :type transport: casperfpga.Transport
    :param use_rpi: If set, override the ``transport`` parameter.
        If True, use the KatcpTransport to talk to a SNAP's
        Raspberry Pi. If False, use the TapcpTransport.
    :type use_rpi: Bool
    """
    n_pols = 2 # Number of polarization the F-engine processes
    pps_source = "board" # After programming set the PPS source to the front panel input
    n_chans_f = 4096 # Number of channels generated by channelizer
    n_chans_per_block = 4 # Granularity with which we can set channels
    adc_demux_factor = 8 # Number of ADC clocks per FPGA clock
    n_interfaces = 2 # Number of available 10GbE interfaces
    n_times_per_packet = 16 # Number of time samples per packet
    packetizer_granularity = 2**5 # Number of 64-bit words ber packetizer step
    n_coeff_shared = 4 # Number of adjacent frequency channels sharing an EQ coefficient
    tge_n_bytes_per_word = 8 # 8 1-byte time samples per 64-bit 10GbE output.
    n_ants_per_board = 1 #: Number of antennas on a board

    def __init__(self, host, feng_id=0, transport=casperfpga.TapcpTransport, use_rpi=None):
        """
        Constructor method
        """
        if use_rpi is not None:
            if use_rpi:
                transport = casperfpga.KatcpTransport
            else:
                transport = casperfpga.TapcpTransport
        self.fpga = casperfpga.CasperFpga(host, transport=transport)
        silence_tftpy()
        self.host = host
        self.logger = logging.getLogger('AtaSnapFengine')
        self.logger.setLevel(logging.DEBUG)
        self.feng_id = feng_id
        if 'nchans' in self.fpga.listdev():
            self.n_chans_f = self.fpga.read_uint('n_chans_f')
        if 'is_8_bit' in self.fpga.listdev():
            self.is_8_bit = bool(self.fpga.read_uint('is_8_bit'))
        else:
            self.is_8_bit = False
        # If the board is programmed, try to get the fpg data
        #if self.is_programmed():
        #    try:
        #        self.fpga.transport.get_meta()
        #    except:
        #        self.logging.warning("Tried to get fpg meta-data from a running board and failed!")

    def _pipeline_get_regname(self, regname):
        """
        Modify register name ``regname`` to comply with pipeline naming
        conventions.

        :param regname: The register name in this pipeline to be accessed.
        :type regname: str

        :return: Expanded register name, matching the spec recognized
            by CasperFpga.
        :rtype: str
        """
        # Do nothing.
        return regname

    def is_programmed(self):
        """
        Returns True if the fpga appears to be programmed
        with a valid F-engine design. Returns False otherwise.
        The test this method uses is searching for the register
        named `version` in the running firmware, so it can
        easily be fooled.

        :return: True if programmed, False otherwise
        :rtype: bool
        """
        if 'version' in self.fpga.listdev():
            version = self.fpga.read_uint('version')
            ver_maj = version >> 13
            ver_min = (version >> 11) & 0b11
            ver_rev = (version >> 8) & 0b11
            ver_bug = version & 0xff
            ver_str = "%d.%d.%d-%d" % (ver_maj, ver_min, ver_rev, ver_bug)
            self.logger.info("FPGA F-Engine version (based on 'version' register) is %s" % ver_str)
            return True
        return False

    def sync_select_input(self, pps_source):
        """
        Select which PPS input is used to drive the design's timing subsystem.

        :param pps_source: Which PPS source should be used. "adc" indicates the ADC5G's sync input.
            "board" indicates the SNAP board's dedicated sync input.
        :type pps_source: str
        """

        assert pps_source in ["adc", "board"], "pps_souce must be either 'adc' or 'board'"
        self.logger.info("Setting PPS source to %s" % pps_source)
        if pps_source == "adc":
            self.fpga.write_int("sync_sel", 0)
        elif pps_source == "board":
            self.fpga.write_int("sync_sel", 1)

    def program(self, fpgfile, force=False, init_adc=True):
        """
        Program a SNAP with a new firmware file.

        :param fpgfile: .fpg file containing firmware to be programmed
        :type fpgfile: str
        :param force: If True, overwrite the existing firmware even if the firmware
            to load appears to already be present. This only makes a difference for
            `TapcpTransport` connections.
        :type force: bool
        :param init_adc: If True, initialize the ADC cards after programming. If False,
            you *must* do this manually before using the firmware using the
            `adc_initialize` method.
        :type init_adc: bool
        """
        # in an abuse of the casperfpga API, only the TapcpTransport has a "force" option
        if isinstance(self.fpga.transport, casperfpga.TapcpTransport):
            self.fpga.transport.upload_to_ram_and_program(fpgfile, force=force)
        else:
            self.fpga.upload_to_ram_and_program(fpgfile)
        self.fpga.get_system_information(fpgfile)
        self.sync_select_input(self.pps_source)
        if init_adc:
            self.adc_initialize()
        self.fpga.write_int(self._pipeline_get_regname("corr_feng_id"), self.feng_id)

    def adc_initialize(self):
        """
        Initialize the ADC interface by performing FPGA<->ADC link training.
        Put the ADC chip in dual-input mode.
        This method must be called after programming a SNAP, and is called
        automatically if using this class's `program` method with init_adc=True.
        """
        import adc5g
        self.logger.info("Configuring ADC->FPGA interface")
        # First reset ADC, then MMCM
        self.fpga.write_int(adc5g.opb.OPB_CONTROLLER, 0b1, blindwrite=True)
        self.fpga.write_int(adc5g.opb.OPB_CONTROLLER, 0b0, blindwrite=True)
        time.sleep(0.001)
        # Set initial config registers
        self.fpga.write_int(adc5g.opb.OPB_CONTROLLER, 0b1, word_offset=1, blindwrite=True)
        self.fpga.write_int(adc5g.opb.OPB_CONTROLLER, 0b0, word_offset=1, blindwrite=True)
        time.sleep(0.001)
        # Is the MMCM locked
        unlocked_count0 = self.fpga.read_uint(adc5g.opb.OPB_CONTROLLER, word_offset=5) >> 16
        unlocked_count1 = self.fpga.read_uint(adc5g.opb.OPB_CONTROLLER, word_offset=5) >> 16
        if unlocked_count0 == unlocked_count1:
            self.logger.info("MMCM is locked")
        else:
            self.logger.warning("MMCM appears unlocked")

        chosen_phase, glitches = adc5g.calibrate_mmcm_phase(self.fpga, 0, ['ss_adc'])
        self.logger.info("Glitches-vs-capture phase: %s" % glitches)
        self.logger.info("Chosen phase: %d" % chosen_phase)
        self.logger.info("Configuring ADCs for dual-input mode")
        adc5g.spi.set_spi_control(self.fpga, 0, adcmode=0b0100, stdby=0, dmux=1, bg=1, bdw=0b11, fs=0, test=0)

    def adc_get_samples(self):
        """
        Get a block of samples from both ADC inputs, captured simultaneously.

        This method requires that the currently programmed fpg file is known.
        This can be achieved either by programming the board with program(<fpgfile>),
        or by running fpga.get_system_information(<fpgfile>) if the board
        was already programmed outside of this class.

        :return: x, y (numpy arrays of ADC sample values)
        :rtype: numpy.ndarray
        """
        if len(self.fpga.snapshots) == 0:
            raise RuntimeError("Please run AtaSnapFengine.program(...) or "
                    "AtaSnapFengine.fpga.get_system_information(...) with the "
                    "loaded bitstream prior to trying to snapshot data")
        d, t = self.fpga.snapshots.ss_adc.read_raw(man_trig=True, man_valid=True)
        d_unpacked = np.fromstring(d['data'], dtype=np.int8)
        x = d_unpacked[0::2]
        y = d_unpacked[1::2]
        return x, y

    def adc_get_stats(self, per_core=False):
        """
        Get the mean value and power, and a count of overflow events for the system's ADCs. Statistics
        are calculated over the last 512k samples, and are computed from samples obtained from all ADC
        channels simultaneously.

        :param per_core: If True, return stats for each ADC core. If false, return stats for each ADC channel.
        :type per_core: bool
        :return: A 3-tuple of numpy.ndarray, with either 4 entries (if per_core=True) or 2 entries (if per_core=False).
            The tuple is (clip_count, mean, mean_power) where clip_count is the number of clipping events in the last
            512k samples, mean is the average of the last 512k samples, and mean_power is the mean power of the last
            512k samples.
            If per_core=True, each array has 4 entries, representing the four ADC cores. Cores 0, 2 digitize the X-pol
            RF input, and cores 1, 3 digitize the Y-pol input. In this case stats are calculated over 256k samples per core.
            If per_core=False, each array has 2 entries, with the first address the X-pol RF input, and the second the Y-pol.
            In this case statistics are calculated over 512k samples per polarization.
        :rtype: (numpy.ndarray, np.ndarray, np.ndarray)
        """
        # First enable the capture
        self.fpga.write_int("stats_enable", 1)
        # Wait for a capture period. 512k samples is <10ms for even slowish clock rates
        time.sleep(0.01)
        # Disable capture
        self.fpga.write_int("stats_enable", 0)
        # Read bram
        # 4 x 32bit values per word (one is a dummy); 16 words
        x = struct.unpack(">64l", self.fpga.read("stats_levels", 4*4*16))
        if per_core:
            n = 4
        else:
            n = 2
        clip_count = np.array(x[1::4]).reshape([16//n, n]).sum(axis=0)
        mean = np.array(x[2::4]).reshape([16//n, n]).mean(axis=0) / (2**16)
        mean_power = np.array(x[3::4]).reshape([16//n, n]).mean(axis=0) / (2**16)
        return clip_count, mean, mean_power

    def adc_get_mismatch(self, n_snapshot=16):
        """
        Get the offset and gain mismatch between the two interleaved cores forming each polarization.

        :param pol: Polarization to interrogate (0 or 1)
        :type pol: int
        :param n_snapshot: Number of snapshots to take. More gives better statistics, but takes longer
        :type n_snapshot: int

        :return: 2x2 array [[pol0 offset, pol0 gain], [pol1 offset, pol1 gain]]
            offset: the number of ADC counts which core 1 is is offset by relative to core 0. E.g. if
            offset=0.2, then the mean of all the core 1 ADC samples is 0.2 higher than the mean of all core 0 samples.

            gain: the relative gain of core 1 vs core 0. E.g., if gain = 1.03, then the mean power of all core 1 samples
            is 1.03 times the mean power of all core 1 samples.

        :rtype: (float, float)
        """
        p0 = np.array([])
        p1 = np.array([])
        for i in range(n_snapshot):
            p0_temp, p1_temp = self.adc_get_samples()
            p0 = np.append(p0, p0_temp)
            p1 = np.append(p1, p1_temp)
        out = np.zeros([2,2])
        out[0,0] = p0[1::2].mean() - p0[0::2].mean()
        out[0,1] = p0[1::2].std() / p0[0::2].std()
        out[1,0] = p1[1::2].mean() - p1[0::2].mean()
        out[1,1] = p1[1::2].std() / p1[0::2].std()

        return out

    def _adc_get_ogp(self):
        """
        Get the offset, gain, and phase registers currently loaded to the ADC.

        :return: 3-tuple of offset, gain, phase register settings.
            Each entry is a np.array with 4 entries, one per ADC core
        :rtype: (np.array, np.array, np.array)
        """
        import adc5g
        offset = np.zeros(4)
        gain = np.zeros(4)
        phase = np.zeros(4)
        for core in range(4):
            offset[core] = adc5g.get_spi_offset(self.fpga, 0, core+1)
            gain[core] = adc5g.get_spi_gain(self.fpga, 0, core+1)
            phase[core] = adc5g.get_spi_phase(self.fpga, 0, core+1)
        return offset, gain, phase

    def _adc_set_ogp(self, offset, gain, adjust=True):#, phase):
        """
        Set the offset, gain, and phase registers of the ADC5G chip.
        Floating values will be rounded to the nearest available ADC setting.
        Set any of the input arguments to `None` to ignore this setting.

        :param offset: list or array of 4 offset register values, one per core.
            Units of offset are ADC LSBs (this function assumes the ADC is in 500mV p2p mode)
        :type offset: list or np.array of integers
        :param gain: list or array of 4 gain register values, one per core.
            Gains are unitless fractions
        :type gain: list or np.array of integers
        :param adjust: If True, apply provided corrections as modifications to currently loaded settings.
            If False, overwrite the current settings with those provided.
        :type adjust: Bool

        :return: offset, gain: The values actually loaded, in units of mV and percent
        """
        import adc5g
        #print("offsets requested", offset)
        #print("gains requested", gain)
        if offset is not None:
            mv_per_lsb = 500. / 256 # Assume the ADC is in its default 500mV range
            offset = [x * mv_per_lsb for x in offset]
        #print("offsets after rescaling", offset)

        if gain is not None:
            gain = [100*(1-x) for x in gain]
        #print("gains after rescaling", gain)

        if adjust:
            # Get current gains
            cur_offset, cur_gain, cur_phase = self._adc_get_ogp()
            #print("Current offsets:", cur_offset)
            #print("Current gain:", cur_gain)
            if offset is not None:
                offset = [offset[i] + cur_offset[i] for i in range(4)]
            if gain is not None:
                gain = [gain[i] + cur_gain[i] for i in range(4)]
        #print("offsets after adjusting current settings", offset)
        #print("gains after adjusting current settings", gain)


        MAX_OFFSET = 50 #mv
        MAX_GAIN = 18 #percent
        for core in range(4):
            if offset is not None:
                if np.abs(offset[core]) > MAX_OFFSET:
                    self.logger.warning("ADC offset %.2f was saturated to %.2f" % (offset[core], MAX_OFFSET))
                    offset[core] = MAX_OFFSET
                adc5g.set_spi_offset(self.fpga, 0, core+1, offset[core])
            if gain is not None:
                if np.abs(gain[core]) > MAX_GAIN:
                    self.logger.warning("ADC gain %.2f was saturated to %.2f" % (gain[core], MAX_GAIN))
                    gain[core] = MAX_GAIN
                adc5g.set_spi_gain(self.fpga, 0, core+1, gain[core])
            #if phase is not None:
            #    adc5g.set_spi_phase(self.fpga, 0, core+1, phase[core])
        return offset, gain

    #def adc_balance(self, n_trial=3, reset=True):
    #    """
    #    Attempt to balance the ADC cores offset and gains, using
    #    the current input signal.

    #    :param n_trial: Number of iterations to compute the correction
    #    :type n_trial: int
    #    :param reset: If True, set all ADC settings to their startup values
    #        before running in the balance algorithm.
    #        If False, start from whatever settings are currently loaded.
    #    :type reset: Bool

    #    :return: offset, gain, phase
    #        The currently loaded offset, gain, and phase setting. Each
    #        is a vector with 4 elements - one per ADC core.
    #    """
    def adc_balance(self):
        """
        Attempt to balance the ADC cores offset and gains, using
        the current input signal.

        :return: offset, gain, phase
            The currently loaded offset and gain setting. Each
            is a vector with 4 elements - one per ADC core.
        """
        reset = True
        n_trial = 1
        if reset:
            self._adc_set_ogp([0,0,0,0], [1,1,1,1], adjust=False)
        c = self.adc_get_mismatch(n_snapshot=30)
        self.logger.info("ADC Balance started with pol 0 offset/gain mismatch %.4f/%.4f" % (c[0,0], c[0,1]))
        self.logger.info("ADC Balance started with pol 1 offset/gain mismatch %.4f/%.4f" % (c[1,0], c[1,1]))
        for i in range(n_trial):
            c = self.adc_get_mismatch(n_snapshot=30)
            #print()
            self.logger.info("ADC Balance %d with pol 0 offset/gain mismatch %.4f/%.4f" % (i, c[0,0], c[0,1]))
            self.logger.info("ADC Balance %d with pol 1 offset/gain mismatch %.4f/%.4f" % (i, c[1,0], c[1,1]))
            self._adc_set_ogp([0, -c[0,0], 0, -c[1,0]], [1, c[0,1], 1, c[1,1]], adjust=True)
        c = self.adc_get_mismatch(n_snapshot=30)
        self.logger.info("ADC Balance finished with pol 0 offset/gain mismatch %.4f/%.4f" % (c[0,0], c[0,1]))
        self.logger.info("ADC Balance finished with pol 1 offset/gain mismatch %.4f/%.4f" % (c[1,0], c[1,1]))

        # Return what we have written rather than what is read back, because the readback
        # command doesn't seem to be working (or is related to the set gains in a non-trivial way)
        return [[0, -c[0,0], 0, -c[1,0]], [1, c[0,1], 1, c[1,1]]]
        #return self._adc_get_ogp()

    def sync_wait_for_pps(self):
        """
        Block until an external PPS trigger has passed.
        I.e., poll the FPGA's PPS count register and do not
        return until is changes.
        """
        self.logger.info('Waiting for PPS to pass')
        count_now = self.sync_get_ext_count()
        while (self.sync_get_ext_count() == count_now):
            time.sleep(0.05)

    def sync_arm(self, manual_trigger=False):
        """
        Arm the FPGA's sync generators for triggering on a 
        subsequent PPS.
        The arming proceedure is the following:
        1. Wait for a PPS to pass using `sync_wait_for_pps`.
        2. Arm the FPGA's sync register to trigger on the next+2 PPS
        3. Compute the time this PPS is expected, based on this computer's clock.
        4. Write this time as a 32-bit UNIX time integer to the FPGA, to record
        the sync event.

        :param manual_trigger: Use a software sync, rather than relying on an external PPS pulse.
            See `sync_manual_trigger` for more information.
        :type manual_trigger: bool

        :return: Sync trigger time, in UNIX format
        :rval: int
        """
        if not manual_trigger:
            self.sync_wait_for_pps()
        self.logger.info('Issuing sync arm')
        self.fpga.write_int('sync_arm', 0)
        self.fpga.write_int('sync_arm', 1)
        self.fpga.write_int('sync_arm', 0)
        time.sleep(0.1)
        sync_time = int(np.ceil(time.time())) + 2
        self.fpga.write_int('sync_sync_time', sync_time)
        if manual_trigger:
            wait_time = sync_time - time.time()
            # wait time should always be positive, unless for some reason
            # writing the sync_time register took an abnormally long time
            if wait_time > 0:
                time.sleep(wait_time)
            self.sync_manual_trigger()
        else:
            self.sync_wait_for_pps()
        return sync_time

    def set_delays(self, delays, load_time=-1, clock_rate_hz=2048000000, sync_time=None, load_resolution=1):
        """
        Set the delay, in units of ADC clock cycles, of a pipeline input.

        :param delay: tuple of delays to apply to a polarization pair [x-pol delay, y-pol delay]
        :type delay: float

        :param load_time: UNIX time at which delays should be loaded, or -1 to load immediately
        :type load_time: int

        :param clock_rate_hz: ADC clock rate in Hz. If None, the clock rate will be computed from
            the observed PPS interval, which could fail if the PPS is unstable or not present.
        :type clock_rate_hz: int

        :param sync_time: The time, in UNIX seconds, at which the F-engine was last synchronized.
            If None, the sync time will be queried from the board using the `get_last_sync_time()` method.
        :type sync_time: int

        :param load_resolution: Delays will be loaded on a spectrum ID which is an integer multiple of 
            ``load_resolution``
        :type load_resolution: int

        :return: None, unless load_time is provided. In this case return the spectrum ID (the spectrum
            count, relative to the F-engine sync time) at which the requested delays will be loaded
        :rval: int

        """
        for delay in delays:
            assert delay <= MAX_SAMPLE_DELAY, "Delay must be between 0 and %d" % (MAX_SAMPLE_DELAY - 1)
        self.fpga.write_int(self._pipeline_get_regname('delay_ctrl'), 0) # disable loads while we configure registers
        if load_time != -1:
            # compute load times
            if sync_time is None:
                sync_time = self.sync_get_last_sync_time()
            if clock_rate_hz is None:
                clock_rate_hz = self.sync_get_fpga_clk_pps_interval() * self.adc_demux_factor
                self.warning("Calling `set_delay` without a clock_rate_hz argument is a bad idea")
            if load_time <= time.time() - 1:
                self.error("Delay load time was <1 second in the future")
                return None
            # Number of seconds after sync
            load_secs = load_time - sync_time
            if load_secs <= 0:
                self.error("Delay load time was %.2f seconds before last sync" % (-load_secs))
                return None
            # ADC clocks after sync
            load_adc_clocks = load_secs * clock_rate_hz
            # Round to whole numbers of spectra
            load_adc_clocks = int(load_adc_clocks) - (int(load_adc_clocks) % (2*self.n_chans_f))
            # Spectrum number
            load_spectra = load_adc_clocks // (2*self.n_chans_f)
            # Round to appropriate resolution
            load_spectra = load_spectra - (load_spectra % load_resolution)
            # FPGA clocks after sync
            load_fpga_clocks = load_adc_clocks // self.adc_demux_factor
            load_fpga_clocks = load_fpga_clocks
            if load_fpga_clocks >= 2**64:
                self.logger.error("Delay load time is too far in the future! (%.2f seconds)" % load_secs)
            self.fpga.write_int(self._pipeline_get_regname("delay_target_load_time_msb"), load_fpga_clocks >> 32)
            self.fpga.write_int(self._pipeline_get_regname("delay_target_load_time_lsb"), load_fpga_clocks & 0xffffffff)

        for pol, delay in enumerate(delays):
            self.fpga.write_int(self._pipeline_get_regname('delay_delay%d_delay') % pol, delay)

        if load_time != -1:
            self.fpga.write_int(self._pipeline_get_regname('delay_ctrl'), 2) # disable immediate and enable timed load
            return load_spectra
        else:
            self.fpga.write_int(self._pipeline_get_regname('delay_ctrl'), 1) # Load delay
            self.fpga.write_int(self._pipeline_get_regname('delay_ctrl'), 0) # disable all loads
            return None

    def get_delay(self, pol):
        """
        Get the currently loaded delay, in units of ADC clock cycles, of a pipeline input.

        :param pol: Polarization to read (0 or 1)
        :type pol: int

        :return: delay, in units of ADC clock cycles
        :rtype: int
        """
        return self.fpga.read_uint(self._pipeline_get_regname('delay_delay%d_loaded' % pol))

    def get_pending_delay(self, pol):
        """
        Get the upcoming delay, in units of ADC clock cycles, of a pipeline input, and
        the time when it will be loaded.

        :param pol: Polarization to read (0 or 1)
        :type pol: int

        :return: (delay, time_to_load) tuple
          delay, in units of ADC clock cycles
          time_to_load, in units of seconds. If negative, represents the number of
          seconds since the delays were loaded.
        :rtype: (int, float)
        """
        delay = self.fpga.read_uint(self._pipeline_get_regname('delay_delay%d_delay' % pol))
        load_clocks = self.fpga.read_uint(self._pipeline_get_regname('delay_time_to_load_msb')) << 32
        load_clocks += self.fpga.read_uint(self._pipeline_get_regname('delay_time_to_load_lsb'))
        if load_clocks > 2**63:
            load_clocks -= 2**64
        load_secs = load_clocks / self.sync_get_fpga_clk_pps_interval()
        return delay, load_secs


    def sync_manual_trigger(self):
        """
        Issue a sync using the F-engine's built-in software trigger.
        This can be useful for single board deployments or testing where
        an external PPS signal may not be available.
        However, a manual sync cannot synchronize multiple boards, and
        will only be aligned to the expected sync time at the ~1s level.
        """
        self.logger.info('Issuing manual sync trigger')
        for i in range(3):
            self.fpga.write_int('sync_arm', 0)
            self.fpga.write_int('sync_arm', 1<<4)
            self.fpga.write_int('sync_arm', 0)

    def sync_get_last_sync_time(self):
        """
        Get the sync time currently stored on this FPGA

        :return: Sync trigger time, in UNIX format
        :rval: int
        """
        return self.fpga.read_uint('sync_sync_time')

    def sync_get_adc_clk_freq(self):
        """
        Infer the ADC clock period by counting FPGA clock ticks
        between PPS events.

        :return: ADC clock rate in MHz
        :rval: float
        """
        adc_count = self.adc_demux_factor * self.sync_get_fpga_clk_pps_interval()
        freq_mhz = adc_count / 1.0e6
        return freq_mhz

    def sync_get_ext_count(self):
        """
        Read the number of external sync pulses which have been received since
        the board was last programmed.

        :return: Number of sync pulses received
        :rval: int
        """
        return self.fpga.read_uint('sync_count')

    def sync_get_fpga_clk_pps_interval(self):
        """
        Read the number of FPGA clock ticks between the last two external sync pulses.

        :return: FPGA clock ticks
        :rval: int
        """
        return self.fpga.read_uint('sync_period')

    def _sync_set_period(self, period):
        """
        Set the period, in FPGA clock ticks, of the internal sync pulse generation logic.
        This period should be divisible by both 6 (an esoteric firmware requirement)
        and the number of points in the design's FFT, and is used to define the accumulation
        length of the firmware's spectrometer mode. This method should be called
        only via `set_accumulation_length`.

        :param period: Number of FPGA clock ticks in a synchronization period.
        :type period: int
        :raises ValueError: If the chosen sync period is not allowed.
        """
        self.logger.info("Setting sync period to %d FPGA clocks" % period)
        # If there is a valid clock and PPS connected, we can turn this into a time
        clocks_per_sec = self.sync_get_fpga_clk_pps_interval()
        if clocks_per_sec == 0:
            self.logger.info("Can't estimate sync period time because no PPS was detected")
        else:
            sync_period_ms = 1000*period / float(clocks_per_sec)
            self.logger.info("Based on the PPS input, sync period is %.2f milliseconds" % sync_period_ms)
        if period % (2*self.n_chans_f):
            self.logger.warning("Sync period %d is not compatible with FFT length %d" % (period, 2*self.n_chans_f))
            raise ValueError("Sync period %d is not compatible with FFT length %d" % (period, 2*self.n_chans_f))
        if period % (5*(self.n_chans_f // 4)):
            self.logger.warning("Sync period %d is not compatible with voltage output reordering." % (period))
            self.logger.warning("Sync period should be a multiple of 5 * n_chans_f/4")
            raise ValueError("Sync period should be a multiple of 5 * n_chans_f/4")
        self.fpga.write_int('timebase_sync_period', period)

    def _sync_get_period(self):
        """
        Get the current firmware sync period, in FPGA clock ticks.

        :return: period Sync period
        :rtype: int
        """
        return self.fpga.read_uint('timebase_sync_period')

    def set_accumulation_length(self, acclen):
        """
        Set the number of spectra to accumulate for the on-board
        spectrometer.

        :param acclen: Number of spectra to accumulate
        :type acclen: int
        """
        self.logger.info('Setting accumulation length to %d spectra' % acclen)
        if acclen % 8:
            self.logger.warning("Accumulation length should be a multiple of 8")
        if acclen % 5:
            self.logger.warning("Accumulation length should be a multiple of 5")
        self._sync_set_period(acclen * self.n_chans_f * 2 // 8) # *2 for real-FFT; /8 for ADC demux

    def get_accumulation_length(self):
        """
        Get the number of spectra currently being accumulated in the on-board spectrometers.

        :return: acclen; Accumulation length
        :rtype int:
        """
        sync_period = self._sync_get_period()
        assert ((8*sync_period) % (self.n_chans_f * 2) == 0), "Got bad sync period! Not an integer number of spectra!"
        acclen = sync_period * 8 // 2 // self.n_chans_f
        return acclen

    def _reorder_channels(self, order, transpose_time=True):
        """
        Reorder the channels such that the channel order[i]
        emerges out of the reorder in position i.
        """
        out_array = np.zeros([self.n_times_per_packet *  self.n_chans_f // self.n_chans_per_block], dtype='>i2')
        if not transpose_time:
            raise NotImplementedError("Reorder only implemented with time fastest ordering")
        # Check input
        order = np.array(order)
        # We must load the reorder map in one go
        assert order.shape[0] == (self.n_chans_f // self.n_chans_per_block)
        # Start points can only be integer multiples of the number of channels in a word
        for o in order:
            assert o < (self.n_chans_f // self.n_chans_per_block)
            assert o % 1 == 0
        # All elements must appear only once
        assert np.unique(order).shape[0] == order.shape[0]
        for xn, x in enumerate(order):
            #print("Mapping channel %d to position %d" % (x, xn))
            for t in range(self.n_times_per_packet):
                out_array[xn * self.n_times_per_packet + t] = x + (t*self.n_chans_f // self.n_chans_per_block)
        
        self.fpga.write(self._pipeline_get_regname('chan_reorder_reorder3_map'), out_array.tobytes())

    def fft_of_detect(self):
        """
        Read the FFT overflow detection register. Will return True if
        an overflow has been detected in the last accumulation period. False otherwise.
        Increase the FFT shift schedule to avoid persistent overflows.

        :return: True if FFT overflowed in the last accumulation period, False otherwise.
        :rtype: bool
        """
        return bool(self.fpga.read_uint(self._pipeline_get_regname('pfb_fft_of')))

    def quant_spec_read(self, pol=0, flush=True, normalize=False):
        """
        Read a single accumulated spectrum of the 4-bit quantized data

        This method requires that the currently programmed fpg file is known.
        This can be achieved either by programming the board with program(<fpgfile>),
        or by running fpga.get_system_information(<fpgfile>) if the board
        was already programmed outside of this class.

        :param pol: Polarization to read
        :type pol: int
        :param flush: If True, throw away one integration prior to getting data.
                      This can be desirable if (eg) EQ coefficients have been recently
                      changed.
        :type flush: Bool
        :param normalize: If True, divide out the accumulation length and firmware
            scaling, returning floating point values. Otherwise, return integers
            and leave these factors present.
        :type normalize: Bool

        :raises AssertionError: if pol is not 0 or 1
        :return: A numpy array containing the polarization's power spectrum
        :rtype: numpy.array
        """
        SCALE = 2**14 # Vacc number representation
        if len(self.fpga.snapshots) == 0:
            raise RuntimeError("Please run AtaSnapFengine.program(...) or "
                    "AtaSnapFengine.fpga.get_system_information(...) with the "
                    "loaded bitstream prior to trying to snapshot data")

        assert pol in [0,1]
        # Get the accumulation length if we need it for scaling
        if normalize:
            acc_len = self.get_accumulation_length()

        self.fpga.write_int("corr_quant_vacc_ss_sel", pol)
        if flush:
            self.fpga.snapshots.corr_quant_vacc_ss_ss0.read_raw()
        d0, t0 = self.fpga.snapshots.corr_quant_vacc_ss_ss0.read_raw()
        d0i = np.array(struct.unpack(">%dI" % (d0["length"] // 4), d0["data"]))
        if normalize:
            d0i = d0i / float(SCALE * acc_len)
        return d0i

    def _filter_spectrum(self, x, medfil_ksize=401, conv_ksize=100):
        """
        Filter the input x (intended to be a spectrum with RFI) first applying
        a median filter to remove interference, and then applying a boxcar
        smoothing filter.

        This method requires the scipy signals library

        :param x: Input signal vector to be filtered
        :type x: numpy.array
        :param medfil_ksize: Size of median filter kernel. Should be odd.
        :type medfil_ksize: int
        :param conv_ksize: Convolution kernel size.
        :type conv_ksize: int

        :return: Filtered and smoothed input vector
        :rtype: numpy.array
        """
        import scipy.signal
        x_mfilt = scipy.signal.medfilt(x, medfil_ksize)
        x_conv = scipy.signal.convolve(x_mfilt, np.ones(conv_ksize), mode='same') / float(conv_ksize)
        return x_conv

    def eq_compute_coeffs(self, target_rms=0.5, medfil_ksize=401, conv_ksize=100, acc_len=50000):
        """
        Get appropriate EQ coefficients to scale FFT output for an appropriate post-quantization
        power target. Do this by grabbing a full bit-precision spectrum, filtering out RFI and smoothing,
        and then computing the scaling required to reach a target power level.

        :param target_rms: The target voltage RMS. This should be specified relative to signed
            data normalized to the range +/-1. I.e., a target_rms of 1./2**7
            represents an RMS of one least-significant bit after quantizing to 8-bits.
            A target_rms of 1./2**3 represents one least-significant bit after quantizing
            to 4-bits.
        :type target_rms: float
        :param medfil_ksize: Size of median filter kernel to use for RFI removal. Should be odd.
        :type medfil_ksize: int
        :param conv_ksize: Convolution kernel size to use for bandpass smoothing.
        :type conv_ksize: int
        :param acc_len: If specified, use this accumulation length for the computation.
            Accumulation length should be sufficiently long to obtain good autocorrelation
            SNR. After the EQ coeffients are obtained, the accumulation length the firmware
            was using before this function was invoked is reloaded.
        :type acc_len: int

        :return: x_coeffs, y_coeffs: A tuple of coefficients. Each is a numpy array of
            floating-point values.
        :rtype: numpy.array, numpy.array
        """

        if acc_len is not None:
            old_acc_len = self.get_accumulation_length()
            self.set_accumulation_length(acc_len)
        xx, yy = self.spec_read(mode='auto', flush=True, normalize=True)
        xx = self._filter_spectrum(xx, medfil_ksize=medfil_ksize, conv_ksize=conv_ksize)
        yy = self._filter_spectrum(yy, medfil_ksize=medfil_ksize, conv_ksize=conv_ksize)
        # Generate coefficients by dividing by 2 (to get the power contribution
        # of one of the real/imag parts, and sqrt-ing to get to voltage
        # The resulting coefficients will make the voltage RMS 1
        x_coeff = 1. / np.sqrt(xx / 2.)
        y_coeff = 1. / np.sqrt(yy / 2.)
        # Divide down the coefficients to get the a scale of 1 least-significant bit
        x_coeff *= float(target_rms)
        y_coeff *= float(target_rms)
        if acc_len is not None:
            self.set_accumulation_length(old_acc_len)
        return x_coeff, y_coeff

    def eq_balance(self, pol, target_rms=2.**-3, cutoff=2., medfil_ksize=401, conv_ksize=50):
        """
        Tweak the EQ coefficients for a polarization to target a particular post-EQ
        RMS.

        :param pol: Polarization to equalize.
        :type pol: int

        :param target_rms: The target voltage RMS. This should be specified relative to signed
            data normalized to the range +/-1. I.e., a target_rms of 1./2**7
            represents an RMS of one least-significant bit after quantizing to 8-bits.
            A target_rms of 1./2**3 represents one least-significant bit after quantizing
            to 4-bits.
        :type target_rms: float

        :param cutoff: The scale, relative to the mean coefficient, at which coeffiecients
            are saturated. For example, if the mean coefficient is 1000, and ``cutoff`` is 2,
            coefficients will saturated at a value of 2000. This allows the bandpass
            to still be visible in the equalized data.
        :type cutoff: float

        :param medfil_ksize: Size of median filter kernel to use for RFI removal. Should be odd.
        :type medfil_ksize: int

        :param conv_ksize: Convolution kernel size to use for bandpass smoothing.
        :type conv_ksize: int

        :return: The loaded coefficients as read back. Note that these will be slightly
            different to the loaded coefficients since they will have been saturated
            and quantized to the specifications of the firmware.
        :rtype: Integer coefficients as returned by ``eq_read_coeffs``
        """
        assert pol in [0, 1], "Polarization must be 0 or 1"
        xc, yc = self.eq_compute_coeffs(target_rms=target_rms, medfil_ksize=medfil_ksize, conv_ksize=conv_ksize)
        xc_mean = xc.mean()
        yc_mean = yc.mean()
        xc[xc>cutoff*xc_mean] = cutoff*xc_mean
        yc[yc>cutoff*yc_mean] = cutoff*yc_mean
        coeffs = [xc, yc]
        self.eq_load_coeffs(pol, coeffs[pol])
        return self.eq_read_coeffs(pol)

    def eq_load_coeffs(self, pol, coeffs):
        """
        Load coefficients with which to multiply data prior to 4-bit quantization.
        Coefficients are rounded and saturated such that they fall in the range (0, 2048),
        with a precision of 2**-5 = 0.03125.
        A single coefficient can be provided, in which case coefficients for all frequency
        channels will be set to this value.
        If an array or list of coefficients are provided, there should be one coefficient
        per frequency channel in the firmware pipeline.

        :param pol: Selects which polarization vectors are being loaded to (0 or 1)
            0 is the first ADC input, 1 is the second.
        :type pol: int
        :param coeffs: The coefficients to load. If `coeffs` is a single number, this value
            is loaded as the coefficient for all frequency channels. If `coeffs`
            is an array or list, it should have length self.n_chans_f / self.n_coeff_shared or
            length self.n_chans_f. If the latter, the coefficients will be decimated by a factor
            of self.n_coeff_shared.
            Element [i] of this vector is the coefficient applied to channels i through i+self.n_coeff_shared-1
            if the array has length self.n_chans_f / self.n_coeff_shared.
            If the array has length self.n_chans_f then element [self.n_coeff_shared*i] is the coefficient
            which will be  applied to channels i through i+self.n_coeff_shared-1.
            Coefficients are quantized to UFix32_5 precision.

        :type coeffs: float, or list / numpy.ndarray

        :raises AssertionError: If an array of coefficients is provided with an invalid size,
            if any coefficients are negative, or if pol is a non-allowed value

        :return: 2-tuple coeffs, bin_pt.
            coeffs: An array of self.n_chans_f indicating the integer coefficients loaded.
            bin_pt: position of binary point with which firmware interprets coefficients.
            Eg: bin_pt=5 means that coefficients are interpreted as coeffs / 2^5

        :rtype: numpy.ndarray, int
        """
        COEFF_BITS = 32 # Bits per coefficient
        COEFF_BP = 5 # binary point position

        n_coeffs = self.n_chans_f // self.n_coeff_shared

        assert pol in [0, 1]
        # If the coefficients provided are a single number
        # set all coefficients to this value
        try:
            coeff = float(coeffs)
            coeffs = [coeff for _ in range(n_coeffs)]
        # Otherwise force numpy array to list
        except TypeError:
            coeffs = list(coeffs)
            if len(coeffs) == self.n_chans_f:
                coeffs = coeffs[::self.n_coeff_shared]
            assert len(coeffs) == n_coeffs
        # Negative equalization coefficients don't make sense!
        for coeff in coeffs:
            assert coeff >= 0
        # Manipulate scaling  so that we can write an integer which
        # will be interpreted as a UFix number.
        coeffs = [min(2**COEFF_BITS - 1, int(c*(2**COEFF_BP))) for c in coeffs] # scale up by binary point and saturate
        if COEFF_BITS == 8:
            coeffs_str = struct.pack('>%dB'%n_coeffs, *coeffs)
        elif COEFF_BITS == 16:
            coeffs_str = struct.pack('>%dH'%n_coeffs, *coeffs)
        elif COEFF_BITS == 32:
            coeffs_str = struct.pack('>%dL'%n_coeffs, *coeffs)
        else:
            raise TypeError("Don't know how to convert %d-bit numbers to binary" % COEFF_BITS)
        self._write_eq_coeffs(self._pipeline_get_regname('eq_pol%d_coeffs' % pol), coeffs_str)
        return np.array(coeffs).repeat(self.n_coeff_shared), COEFF_BP

    def _write_eq_coeffs(self, regname, coeff_str):
        """
        Write binary coefficients `coeff_str`, to register name `regname`
        """
        self.fpga.write(regname, coeffs_str)

    def eq_read_coeffs(self, pol, return_float=False):
        """
        Read currently loaded coefficients for one polarization.

        :param pol: Selects which polarization vectors are being read to (0 or 1)
            0 is the first ADC input, 1 is the second.
        :type pol: int
        :param return_float: If True, return floating-point coefficients as interpretted by the SNAP
            If False, return integer coefficients and a binary point position.
        :type return_float: Bool

        :return: If return_float: coeffs; If not return_float: 2-tuple coeffs, bin_pt.
            coeffs: An array of self.n_chans_f indicating the coefficients loaded.
            bin_pt: If return_float=False, this is the position of binary point
            with which firmware interprets coefficients.
            Eg: bin_pt=5 means that coefficients are interpreted as coeffs / 2^5

        :rtype: numpy.ndarray or numpy.ndarray, int
        """

        COEFF_BITS = 32 # Bits per coefficient
        COEFF_BP = 5 # binary point position
        n_coeffs = self.n_chans_f // self.n_coeff_shared

        assert pol in [0, 1]

        raw = self.fpga.read(self._pipeline_get_regname('eq_pol%d_coeffs' % pol), n_coeffs*4)
        coeffs = np.array(struct.unpack('>%dI' % n_coeffs, raw)).repeat(self.n_coeff_shared)
        if return_float:
            return coeffs / 2.0**COEFF_BP
        else:
            return coeffs, COEFF_BP
        

    def eq_load_test_vectors(self, pol, tv):
        """
        Load test vectors for the Voltage pipeline test vector injection module.

        :param pol: Selects which polarization vectors are being loaded to (0 or 1)
            0 is the first ADC input, 1 is the second.
        :type pol: int
        :param tv: Test vectors to be loaded. `tv` should have self.n_chans_f
            elements. tv[i] is the test value for channel i.
            Each value should be an 8-bit number - the most-significant
            4 bits are interpretted as the 4-bit, signed, real part of
            the data stream. The least-significant 4 bits are interpretted
            as the 4-bit, signed, imaginary part of the data stream.
        :type tv: numpy.ndarray or list of ints
        :raises AssertionError: If an array of test vectors is provided with an invalid size,
            or if pol is a non-allowed value
        """
        tv = list(tv)
        assert len(tv) == self.n_chans_f
        assert pol in [0, 1]
        tv_8bit = [x%256 for x in tv]
        tv_8bit_str = struct.pack('>%dB'%self.n_chans_f, *tv_8bit)
        self.fpga.write(self._pipeline_get_regname('eqtvg_pol%d_tv' % pol), tv_8bit_str)

    def eq_test_vector_mode(self, enable):
        """
        Turn on or off the test vector mode downstream of the 4-bit
        quantizers. This mode can be used to replace the
        FFT output in the voltage data path with an arbitrary pattern which can
        be set with `eq_load_test_vectors`

        :param enable: True to turn on the test mode, False to turn off
        :type enable: bool
        """
        if enable:
            self.logger.info("Turning ON post-EQ test-vectors")
        else:
            self.logger.info("Turning OFF post-EQ test-vectors")
        self.fpga.write_int(self._pipeline_get_regname('eqtvg_tvg_en'), int(enable))

    def spec_test_vector_mode(self, enable):
        """
        Turn on or off the test vector mode in the spectrometer data path.
        This mode replaces the FFT output in the data path with 12 bit counter
        which occupies the most significant bits of the imaginary part of the FFT
        output.
        I.e. when enabled, the imaginary part of each spectrum is a ramp from
        0..4095 / 2**17

        :param enable: True to turn on the test mode, False to turn off
        :type enable: bool
        """
        if enable:
            self.logger.info("Turning ON Spectrometer test-vectors")
        else:
            self.logger.info("Turning OFF Spectrometer test-vectors")
        self.fpga.write_int('spec_tvg_tvg_en', int(enable))

    def spec_read(self, mode="auto", flush=False, normalize=False):
        """
        Read a single accumulated spectrum.

        This method requires that the currently programmed fpg file is known.
        This can be achieved either by programming the board with program(<fpgfile>),
        or by running fpga.get_system_information(<fpgfile>) if the board
        was already programmed outside of this class.

        :param mode: "auto" to read an autocorrelation for each of the X and Y pols.
            "cross" to read a cross-correlation of Xconj(Y).
        :type mode: str:
        :param flush: If True, throw away one integration prior to getting data.
                      This can be desirable if (eg) EQ coefficients have been recently
                      changed.
        :type flush: Bool
        :param normalize: If True, divide out the accumulation length and firmware
            scaling, returning floating point values. Otherwise, return integers
            and leave these factors present.
        :type normalize: Bool

        :raises AssertionError: if mode is not "auto" or "cross"
        :return: If mode="auto": A tuple of two numpy arrays, xx, yy, containing
            a power spectrum from the X and Y polarizations.
            If mode="cross": A complex numpy array containing the cross-power
            spectrum of Xconj(Y).
        :rtype: numpy.array
        """
        SCALE = 2**48 # Vacc number representation
        if len(self.fpga.snapshots) == 0:
            raise RuntimeError("Please run AtaSnapFengine.program(...) or "
                    "AtaSnapFengine.fpga.get_system_information(...) with the "
                    "loaded bitstream prior to trying to snapshot data")

        assert mode in ["auto", "cross"]
        if mode == "auto":
            v = 0
        else:
            v = 1
        self.fpga.write_int(self._pipeline_get_regname("corr_vacc_ss_sel"), v)
        ss0 = self.fpga.snapshots[self._pipeline_get_regname('corr_vacc_ss_ss0')]
        ss1 = self.fpga.snapshots[self._pipeline_get_regname('corr_vacc_ss_ss1')]
        ss2 = self.fpga.snapshots[self._pipeline_get_regname('corr_vacc_ss_ss2')]
        ss3 = self.fpga.snapshots[self._pipeline_get_regname('corr_vacc_ss_ss3')]

        # Get the accumulation length if we need it for scaling
        if normalize:
            acc_len = self.get_accumulation_length()

        if flush:
            ss0.read_raw()

        ss0.arm() # This arms all RAMs
        d0, t0 = ss0.read_raw(arm=False)
        d1, t1 = ss1.read_raw(arm=False)
        d2, t2 = ss2.read_raw(arm=False)
        d3, t3 = ss3.read_raw(arm=False)
        d0i = struct.unpack(">%dq" % (d0["length"] // 8), d0["data"])
        d1i = struct.unpack(">%dq" % (d1["length"] // 8), d1["data"])
        d2i = struct.unpack(">%dq" % (d2["length"] // 8), d2["data"])
        d3i = struct.unpack(">%dq" % (d3["length"] // 8), d3["data"])
        if mode == "auto":
            xx_0  = d0i[0::2]
            xx_1  = d1i[0::2]
            xx_2  = d2i[0::2]
            xx_3  = d3i[0::2]
            yy_0  = d0i[1::2]
            yy_1  = d1i[1::2]
            yy_2  = d2i[1::2]
            yy_3  = d3i[1::2]
            xx = np.zeros(self.n_chans_f, dtype=np.int64)
            yy = np.zeros(self.n_chans_f, dtype=np.int64)
            for i in range(self.n_chans_f // 4):
                xx[4*i]   = xx_0[i]
                xx[4*i+1] = xx_1[i]
                xx[4*i+2] = xx_2[i]
                xx[4*i+3] = xx_3[i]
                yy[4*i]   = yy_0[i]
                yy[4*i+1] = yy_1[i]
                yy[4*i+2] = yy_2[i]
                yy[4*i+3] = yy_3[i]
            if normalize:
                xx = xx / float(SCALE * acc_len)
                yy = yy / float(SCALE * acc_len)
            return xx, yy
        elif mode == "cross":
            xy_0_r = d0i[0::2]
            xy_0_i = d0i[1::2]
            xy_1_r = d1i[0::2]
            xy_1_i = d1i[1::2]
            xy_2_r = d2i[0::2]
            xy_2_i = d2i[1::2]
            xy_3_r = d3i[0::2]
            xy_3_i = d3i[1::2]
            xy = np.zeros(self.n_chans_f, dtype=complex)
            for i in range(self.n_chans_f // 4):
                xy[4*i]   = xy_0_r[i] + 1j*xy_0_i[i]
                xy[4*i+1] = xy_1_r[i] + 1j*xy_1_i[i]
                xy[4*i+2] = xy_2_r[i] + 1j*xy_2_i[i]
                xy[4*i+3] = xy_3_r[i] + 1j*xy_3_i[i]
            if normalize:
                xy = xy / float(SCALE * acc_len)
            return xy

    def spec_plot(self, mode="auto"):
        """
        Plot an accumulated spectrum using the matplotlib library.
        Frequency axis is infered from the ADC clock frequency detected with
        `sync_get_adc_clk_freq`.

        :param mode: "auto" to plot a power spectrum from the X and Y
            polarizations on separate subplots.
            "cross" to plot the magnitude and phase of a complex-valued
            cross-power spectrum of the two polarizations.
        :type mode: str:
        :raises AssertionError: if mode is not "auto" or "cross"
        """
        from matplotlib import pyplot as plt
        assert mode in ["auto", "cross"]
        freq_range = np.linspace(0, self.sync_get_adc_clk_freq() / 2, self.n_chans_f + 1)[0:-1]
        if mode == "auto":
            self.logger.info("Grabbing auto-correlation spectra")
            x, y = self.spec_read(mode=mode, normalize=True)
            self.logger.info("Plotting spectra")
            plt.figure()
            plt.subplot(2,1,1)
            plt.title("XX")
            plt.semilogy(freq_range, x)
            plt.ylabel('Power [arb ref]')
            plt.xlabel('Frequency [MHz]')
            plt.subplot(2,1,2)
            plt.title("YY")
            plt.semilogy(freq_range, y)
            plt.ylabel('Power [arb ref]')
            plt.xlabel('Frequency [MHz]')
            plt.show()
        elif mode == "cross":
            self.logger.info("Grabbing auto-correlation spectrum")
            xy = self.spec_read(mode=mode, normalize=True)
            self.logger.info("Plotting spectra")
            plt.figure()
            plt.subplot(2,1,1)
            plt.title("abs(X*Y)")
            plt.semilogy(freq_range, np.abs(xy))
            plt.ylabel('Power [arb ref]')
            plt.xlabel('Frequency [MHz]')
            plt.subplot(2,1,2)
            plt.title("angle(X*Y)")
            plt.plot(freq_range, np.angle(xy))
            plt.ylabel('Phase [radians]')
            plt.xlabel('Frequency [MHz]')
            plt.show()

    def spec_set_destination(self, dest_ip):
        """
        Set the destination IP address for spectrometer packets.

        :param dest_ip: Destination IP address. E.g. "10.0.0.1"
        :type dest_ip: str
        """
        self.logger.info('Setting spectrometer packet destination to %s' % dest_ip)
        ip_int = _ip_to_int(dest_ip)
        self.fpga.write_int(self._pipeline_get_regname("corr_dest_ip"), ip_int)

    def eth_set_mode(self, mode="voltage"):
        """
        Set the 10GbE output stream to either
        "voltage" or "spectra" mode.
        To prevent undesired behaviour, this method will
        disable Ethernet transmission prior to switching. Transmission
        should be re-enabled if desired using `eth_enable_output`.

        :param mode: "voltage" or "spectra"
        :type mode: str
        :raises AssertionError: If mode is not an allowed value
        """
        assert mode in ["voltage", "spectra"]
        # Disbale the ethernet output before doing anything
        self.eth_enable_output(enable=False)
        if mode == "voltage":
             self.fpga.write_int(self._pipeline_get_regname("eth_mux_use_voltage"), 1)
        elif mode == "spectra":
             self.fpga.write_int(self._pipeline_get_regname("eth_mux_use_voltage"), 0)

    def eth_enable_output(self, enable=True, interface='all'):
        """
        Enable the 10GbE output datastream. Only do this
        after appropriately setting an output configuration and
        setting the pipeline mode with `eth_set_mode`.
        For spectra mode, prior to enabling Ethernet the destination
        address should be set with `spec_set_destination`.
        For voltage mode, prior to enabling Ethernet configuration should
        be loaded with `select_output_channels`

        :param enable: Set to True to enable Ethernet transmission, or False to disable.
        :type enable: bool
        :param interface: Which physical interface to enable / disable.
        :type interface: integer or 'all'
        """
        ENABLE_MASK =  0x00000002
        if interface == 'all':
            interfaces = range(self.n_interfaces)
        else:
            interfaces = [int(interface)]
        for i in interfaces:
            v = self.fpga.read_uint("eth%d_ctrl" % i)
            v = v &~ ENABLE_MASK
            if enable:
                v = v | ENABLE_MASK
            self.fpga.write_int("eth%d_ctrl" % i, v)

    def eth_reset(self, interface='all'):
        """
        Reset the Ethernet core. This method will clear the reset after asserting,
        and will leave the transmission stream disabled.
        Reactivate the Ethernet core with `eth_enable_output`

        :param interface: Which physical interface to enable / disable.
        :type interface: integer or 'all'
        """
        RST_MASK = 0x00040001 # both stats and core resets
        if interface == 'all':
            interfaces = range(self.n_interfaces)
        else:
            interfaces = [int(interface)]
        for i in interfaces:
            self.eth_enable_output(enable=False, interface=i)
            v = self.fpga.read_uint("eth%d_ctrl" % i)
            v = v | RST_MASK
            self.fpga.write_int("eth%d_ctrl" % i, v)
            v = v &~ RST_MASK
            self.fpga.write_int("eth%d_ctrl" % i, v)

    def eth_print_counters(self):
        """
        Print ethernet statistics counters from all ethernet cores.
        This is a simple wrapper around casperfpgas gbes.read_counters() method.
        """
        for i in self.fpga.gbes:
            print("%s:" % i.name, i.read_counters())

    def eth_set_dest_port(self, port, interface='all'):
        """
        Set the destination UDP port for output 10GbE packets.

        :param port: UDP port to which traffic should be sent.
        :type port: int
        :param interface: Which physical interface to manipulate
        :type interface: integer or 'all'
        """
        PORT_MASK = (0xffff << 2)
        if interface == 'all':
            interfaces = range(self.n_interfaces)
        else:
            interfaces = [int(interface)]
        for i in interfaces:
            v = self.fpga.read_uint("eth%d_ctrl" % i)
            v = v &~ PORT_MASK
            v = v | (port << 2)
            self.fpga.write_int("eth%d_ctrl" % i, v)

    def change_feng_id(self, feng_id):
        """
        Update the Fengine ID field of both spectrometer packets and voltage packets,
        without otherwise effecting the configuration of a running board.

        Also update this instance's `feng_id` attribute

        :param feng_id: New F-Engine ID for this instance
        :type feng_id: int
        """
        self.feng_id = feng_id
        self.write_int("corr_feng_id", self.feng_id)
        for interface in range(self.n_interfaces):
            headers = self._read_headers(interface)
            for i in range(len(headers)):
                headers[i]['feng_id'] = feng_id
            self._populate_headers(interface, headers)
        

    def select_output_channels(self, start_chan, n_chans, dests=['0.0.0.0'], n_interfaces=None, n_bits=4, nchans_per_packet_limit=None):
        """
        Select the range of channels which the voltage pipeline should output.

        Example usage:
            Send channels 0..255 to 10.0.0.1:
                select_output_channels(0, 256, dests=['10.0.0.1'])
            Send channels 0..255 to 10.0.0.1, and 256..512 to 10.0.0.2
                select_output_channels(0, 512, dests=['10.0.0.1', '10.0.0.2'])

        :param start_chan: First channel to output
        :type start_chan: int
        :param n_chans: Number of channels to output
        :type n_chans: int
        :param dests: List of IP address strings to which data should be sent.
            The first n_chans / len(dests) will be sent to dest[0], etc..
        :type dests: list of str
        :param n_interfaces: Number of 10GbE interfaces to use. Should be <= self.n_interfaces
            Default to using all available interfaces.
        :type n_interface: int
        :param nchans_per_packet_limit: If not None, limits the number of channels per packet to
            min(nchans_per_packet_limit, actual-maximum).
        :type nchans_per_packet_limit: int

        :raises AssertionError: If the following conditions aren't met:
            `start_chan` should be a multiple of self.n_chans_per_block (4)
            `n_chans` should be a multiple of self.n_chans_per_block (4)
            `interface` should be <= self.n_interfaces

        :return: A dictionary, keyed by destination IP, with values corresponding to the
            ranges of channels destined for this IP.
            Eg, if sending 512 channels over two destinations
            '10.0.0.10' and '10.0.0.11', this function might return
            {'10.0.0.10': [0,1,..,255], '10.0.0.11': [256,257,..,511]}
        :rtype: dict
        """

        # Each 10GbE core in the design has its own packetizer.
        # Each packetizer has internal state which changes every packetizer_granularity
        # FPGA clock ticks (each clock tick = one 64-bit word).
        # For each packetizer step, a block of packetizer_granularity words can
        # be marker either
        #    1. The first block in a packet
        #    2. A block in the middle of a packet
        #    3. The last block in a packet
        #    4. Not part of a valid block
        # Accordingly, the block will be marked as valid (or not) and a 
        # 2-word header, will be inserted before the block of data, or an
        # EOF pulse will be inserted at the end of the block.

        # It is the job of the upstream reordering to ensure that the block immediately
        # preceding the first block of a packet contains data which is not to be sent.
        # This creates the space for header insertion.
        # Upstream reordering should also intersperse channels to be sent with those
        # to be discarded, in order to limit the output data rate to <10Gb/s

        # In the event that 4-bit mode is used, the same data is sent to multiple
        # packetizers, and this function should ensure half the channels are sent from
        # each port.
        # In the event that 8-bit mode is used, 1/n_interfaces of the total generated
        # channels are sent to each packetizer, and marking of packet boundaries should
        # be dealt with accordingly.

        # Currently, the only mode allowed outputs data in [slowest to fastest]
        # chan x time x polarization x complexity ordering, though the firmware
        # also has the capability to generate data in
        # chan x time x chans-per-packet x pol x complexity ordering.
        

        # Data by first reordering n_chans_f * n_times_per_packet
        # spectra using a programmable reorder. This reorder operates on
        # n_chans_f * n_times_per_packet / nchans_per_block words, with each word
        # 8+8 bits x nchans_per_block x 2 [pols] wide.

        feng_id = self.feng_id

        # default to using all the interfaces
        n_interfaces = n_interfaces or self.n_interfaces
        assert n_interfaces <= self.n_interfaces

        # define maximum number of channels per packet such that max packet
        # size is 8 kByte + header
        assert n_bits in [4,8], "Only 4- or 8-bit output modes are supported!"
        max_chans_per_packet = 8*8192 // (2*n_bits) // self.n_times_per_packet // 2
        if nchans_per_packet_limit is not None:
            max_chans_per_packet = min(max_chans_per_packet, nchans_per_packet_limit)

        if n_bits == 8:
            raise NotImplementedError("8-bit mode not yet implemented")

        # Set the firmware bitwidth register
        if n_bits == 8:
            self.fpga.write_int('chan_reorder_use_8bit', 1)
        else:
            self.fpga.write_int('chan_reorder_use_8bit', 0)

        # Figure out the channel granularity of the packetizer. This operates
        # in blocks of packetizer_granularity 64-bit words.
        # For now, we only consider case with time the faster axis.
        times_per_word = 64 // (2*2*n_bits)
        # This should always be True for reasonable firmware
        assert self.packetizer_granularity % times_per_word == 0, 'self.packetizer_granularity % times_per_word ({} % {}) != 0'.format(self.packetizer_granularity, times_per_word)
        packetizer_chan_granularity = self.packetizer_granularity // times_per_word

        # We reorder n_chans_per_block as parallel words, so must deal with
        # start / stop points with that granularity
        assert start_chan % self.n_chans_per_block == 0, 'start_chan % self.n_chans_per_block ({} % {}) != 0'.format(start_chan, self.n_chans_per_block)
        n_dests = len(dests)
        # Also Demand that the number of channels can be equally divided
        # among the destination addresses
        assert n_chans % (n_dests * self.n_chans_per_block) == 0, 'n_chans % (n_dests * self.n_chans_per_block) ({} % {}) != 0'.format(n_chans, (n_dests * self.n_chans_per_block))
        # Number of channels per destination is now gauranteed to be an integer
        # multiple of n_chans_per_block
        n_chans_per_destination = n_chans // n_dests
        # If the channels per destination is > the max, then split into multiple
        # packets
        n_packets_per_destination = int(np.ceil(n_chans_per_destination / max_chans_per_packet))
        # Channels should be able to be divided up into packets equally
        assert n_chans_per_destination % n_packets_per_destination == 0, 'n_chans_per_destination % n_packets_per_destination ({} % {}) != 0'.format(n_chans_per_destination, n_packets_per_destination)
        n_chans_per_packet = n_chans_per_destination  // n_packets_per_destination
        # Number of channels per packet should be a multiple of the reorder granularity
        assert n_chans_per_packet % self.n_chans_per_block == 0, 'n_chans_per_packet % self.n_chans_per_block ({} % {}) != 0'.format(n_chans_per_packet, self.n_chans_per_block)
        # Number of channels per packet should be a multiple of packetizer granularity
        assert n_chans_per_packet % packetizer_chan_granularity == 0, 'n_chans_per_packet % packetizer_chan_granularity ({} % {}) != 0'.format(n_chans_per_packet, packetizer_chan_granularity)
        n_slots_per_packet = n_chans_per_packet // packetizer_chan_granularity
        # Can't send more than all the channels!
        assert start_chan + n_chans <= self.n_chans_f, 'start_chan + n_chans > self.n_chans_f ({} > {})'.format(start_chan + n_chans, self.n_chans_f)

        self.logger.info('Start channel: %d' % start_chan)
        self.logger.info('Number of channels to send: %d' % n_chans)
        self.logger.info('Number of interfaces to be used: %d' % n_interfaces)
        self.logger.info('Number of interfaces available: %d' % self.n_interfaces)

        self.logger.info('Number of destinations: %d' % n_dests)
        self.logger.info('Number of channels per destination: %d' % n_chans_per_destination)
        self.logger.info('Number of channels per packet: %d' % n_chans_per_packet)

        # First, for simplicity, duplicate the destination list so that
        # we can deal exclusively in packets, with nominally 1 packet per destination,
        # even if some destinations appear more than once.
        dup_dests = []
        for dest in dests:
            for i in range(n_packets_per_destination):
                dup_dests += [dest]
        dests = dup_dests

        # Divide up each packetizer input stream of n_times_per_pkt * n_chans_f
        # into blocks of packetizer_chan_granularity
        packetizer_n_blocks = self.n_chans_f // packetizer_chan_granularity
        # Initialize variable for the headers
        headers = [
                      [
                          {
                               'first': False,
                               'valid': False,
                               'last': False,
                               'dest': '0.0.0.0',
                               'chans': [0] * packetizer_chan_granularity,
                               'feng_id' : self.feng_id,
                               'n_chans' : n_chans_per_packet,
                               'is_8_bit' : n_bits == 8,
                               'is_time_fastest' : True,
                          } for i in range(packetizer_n_blocks)
                      ]
                  for j in range(n_interfaces)]

        chan_reorder_map = -1 * np.ones(self.n_chans_f, dtype=np.int32)

        # How many slots packetizer blocks do we need to use?
        # Lazily force data rate out of each interface to be the same
        n_packets = len(dup_dests)
        assert n_packets % n_interfaces == 0, "Number of destination packets (%d) does not divide evenly betweed %d interfaces" % n(n_packets, _interfaces)
        available_blocks = packetizer_n_blocks * n_interfaces
        needed_blocks = n_chans // packetizer_chan_granularity
        spare_blocks = available_blocks - needed_blocks

        self.logger.info('Available blocks: %s' % available_blocks)
        self.logger.info('Required blocks: %s' % needed_blocks)
        self.logger.info('Spare blocks: %s' % spare_blocks)

        spare_blocks_per_packet = int(np.floor(spare_blocks / n_packets))
        self.logger.info('Spare blocks per packet: %s' % spare_blocks_per_packet)

        # So, however many packetizer blocks sending a packet takes, after the last
        # block in packet, the next `spare_blocks_per_packet` can be marked invalid

        # Now start allocating channels to slots
        interface = 0
        slot = [0 for _ in range(n_interfaces)]
        input_chan_id = 0
        slot_start_chan = start_chan
        for p in range(n_packets):
            for s in range(n_slots_per_packet):
                headers[interface][slot[interface]]['first'] = s==0
                headers[interface][slot[interface]]['valid'] = True
                headers[interface][slot[interface]]['last'] = s==(n_slots_per_packet-1)
                headers[interface][slot[interface]]['dest'] = dup_dests[p]
                headers[interface][slot[interface]]['chans'] = range(slot_start_chan, slot_start_chan + packetizer_chan_granularity)
                input_chan_id = slot[interface] * packetizer_chan_granularity
                #print(p, s, input_chan_id)
                chan_reorder_map[input_chan_id : input_chan_id + packetizer_chan_granularity] = range(slot_start_chan, slot_start_chan + packetizer_chan_granularity)
                slot_start_chan += packetizer_chan_granularity
                slot[interface] += 1
            # If we are in 4-bit mode, the data going in to both interfaces is the same,
            # so the next interface should start at the slot after the interface we have just used
            if n_bits == 4:
                slot[(interface + 1) % n_interfaces] = slot[interface]
            # After a packet we have dead time
            slot[interface] += spare_blocks_per_packet
            interface = (interface + 1) % n_interfaces
            
        #for i in range(n_interfaces):
        #    for j in range(packetizer_n_blocks):
        #        print(i,j,headers[i][j])
        # Load the headers
        for i in range(n_interfaces):
            self._populate_headers(i, headers[i])
        
        # Load the chan reorder map

        # reduce the channel reorder map by the number of parallel chans in a reorder word
        chan_reorder_map = chan_reorder_map[::self.n_chans_per_block]
        for cn, c in enumerate(chan_reorder_map):
            if c == -1:
                continue
            assert (c % self.n_chans_per_block) == 0
            chan_reorder_map[cn] /= self.n_chans_per_block
        # fill in the gaps (indicated by -1) in the above map with allowed channels we haven't used
        # Note that you _cannot_ repeat channels in the map, since we aren't double buffering
        possible_chans = list(range(0, self.n_chans_f // self.n_chans_per_block))
        for c in chan_reorder_map:
            if c == -1:
                continue
            possible_chans.remove(c)
        for i in range(len(chan_reorder_map)):
            if chan_reorder_map[i] == -1:
                chan_reorder_map[i] = possible_chans.pop(0)
        self._reorder_channels(chan_reorder_map)

        # Return a dictionary, keyed by destination address, where each entry is the range of channels being
        # send to that address.
        rv = {}
        for dn, d in enumerate(dests):
            rv[d] = list(range(start_chan + dn*n_chans_per_destination,
                          start_chan + (dn+1)*n_chans_per_destination))
        return rv
        

    def _populate_headers(self, interface, headers):
        """
        Populate the voltage mode packetizer header fields.

        :param interface: The 10GbE interface to populate
        :type interface: int
        :param headers: A list of header dictionaries to populate
        :type headers: list

        Entry `i` of the `headers` list is written to packetizer header BRAM index `i`.
        This represents the control word associated with the `i`th data sample block
        after a sync pulse. Each data block is self.packetizer_granularity words.

        Each `headers` entry should be a dictionary with the following fields:
          - `first`: Boolean, indicating this sample block is the first in a packet.
          - `valid`: Boolean, indicating this sample block contains valid data.
          - `last`: Boolean, indicating this is the last valid sample block in a packet.
          - `is_8_bit`: Boolean, indicating this packet contains 8-bit data.
          - `is_time_fastest`: Boolean, indicating this packet has a payload in
            channel [slowest] x time x polarization [fastest] order.
          - `n_chans`: Integer, indicating the number of channels in this data block's packet.
          - `chans`: list of ints, indicating the channels present in this data block. The zeroth element is the first channel in this block.
          - `feng_id`: Integer, indicating the F-Engine ID of this block's data.
            This is usually always `self.feng_id`, but may vary if one board is spoofing
            traffic from multiple boards.
          - `dest` : String, the destination IP of this data block (eg "10.10.10.100")
        """

        h_bytestr = b''
        ip_bytestr = b''
        for h in headers:
            header_word = (int(h['last']) << 58) \
                        + (int(h['valid']) << 57) \
                        + (int(h['first']) << 56) \
                        + (int(h['is_8_bit']) << 49) \
                        + (int(h['is_time_fastest']) << 48) \
                        + ((h['n_chans'] & 0xffff) << 32) \
                        + ((h['chans'][0] & 0xffff) << 16) \
                        + ((h['feng_id'] & 0xffff) << 0)
            h_bytestr += struct.pack('>Q', header_word)
            ip_bytestr += struct.pack('>I', _ip_to_int(h['dest']))
        self.fpga.write('packetizer%d_ips' % interface, ip_bytestr)
        self.fpga.write('packetizer%d_header' % interface, h_bytestr)

    def _read_headers(self, interface, n_words=None, offset=0):
        """
        Get the header entries from one of this board's packetizers.

        :param interface: The 10GbE interface to populate
        :type interface: int
        
        :return: headers
        :rtype: list

        Entry `i` of the `headers` list represents the contents of header BRAM index `i`.
        This represents the control word associated with the `i`th data sample block
        after a sync pulse. Each data block is self.packetizer_granularity words.

        Each `headers` entry should be a dictionary with the following fields:
          - `first`: Boolean, indicating this sample block is the first in a packet.
          - `valid`: Boolean, indicating this sample block contains valid data.
          - `last`: Boolean, indicating this is the last valid sample block in a packet.
          - `is_8_bit`: Boolean, indicating this packet contains 8-bit data.
          - `is_time_fastest`: Boolean, indicating this packet has a payload in
            channel [slowest] x time x polarization [fastest] order.
          - `n_chans`: Integer, indicating the number of channels in this data block's packet.
          - `chans`: list of ints, indicating the channels present in this data block. The zeroth element is the first channel in this block.
          - `feng_id`: Integer, indicating the F-Engine ID of this block's data.
            This is usually always `self.feng_id`, but may vary if one board is spoofing
            traffic from multiple boards.
          - `dest` : String, the destination IP of this data block (eg "10.10.10.100")
        """

        if n_words is None:
            n_words = self.n_chans_f * self.n_times_per_packet * self.n_pols // self.tge_n_bytes_per_word // self.packetizer_granularity
        hs_raw = self.fpga.read('packetizer%d_header' % interface, 8*n_words, offset=8*offset)
        ips_raw = self.fpga.read('packetizer%d_ips' % interface, 4*n_words, offset=4*offset)
        hs = struct.unpack('>%dQ' % n_words, hs_raw)
        ips = struct.unpack('>%dI' % n_words, ips_raw)
        headers = []
        for dn, d in enumerate(hs):
            headers += [{}]
            headers[-1]['feng_id'] = (d >> 0) & 0xffff
            headers[-1]['chans'] = (d >> 16) & 0xffff
            headers[-1]['n_chans'] = (d >> 32) & 0xffff
            headers[-1]['is_time_fastest'] = bool((d >> 48) & 1)
            headers[-1]['is_8_bit'] = bool((d >> 49) & 1)
            headers[-1]['first'] = bool((d >> 56) & 1)
            headers[-1]['valid'] = bool((d >> 57) & 1)
            headers[-1]['last'] = bool((d >> 58) & 1)
            headers[-1]['dest'] = _int_to_ip(ips[dn])
        return headers
        

    #def get_channel_assignments(self):
    #    """
    #    Get information about the channels currently being output.

    #    :return: A list of information about channel output blocks. Each list entry
    #        is a dictionary with the following fields:
    #        'interface' : An integer indicating the physical port number from which this
    #                      block of channels is being transmitted.
    #        'ant'       : An integer indicating the antenna number (according to the
    #                      packet headers) associated with this channel block.
    #        'header_chan' : An integer indicating the channel number (according to the
    #                        packet headers) associated with this channel block).
    #        'dest_ip'   : A string indicating the destination IP address for this
    #                      block of packets.
    #        'chans'     : A list of integer channel numbers which are present in this
    #                      block of channels.
    #    """
    #    PARALLEL_CHANS = 4
    #    new_chan_map = list(struct.unpack('>%dH' % (self.n_chans_f // PARALLEL_CHANS), self.fpga.read('chan_reorder_reorder3_map1', 2*(self.n_chans_f//PARALLEL_CHANS))))
    #    n_slots = self.n_interfaces * self.n_chans_out // self.n_chans_per_packet
    #    outputs = []
    #    for slot in range(n_slots):
    #        chans_p = new_chan_map[slot * (self.n_chans_per_packet // PARALLEL_CHANS) : (slot+1) * (self.n_chans_per_packet // PARALLEL_CHANS)]
    #        chans = []
    #        for c in chans_p:
    #            chans += list(range(PARALLEL_CHANS * c, PARALLEL_CHANS * (c+1)))
    #        print(chans)
    #        interface = slot % self.n_interfaces
    #        dest_ip = _int_to_ip(self.fpga.read_uint('packetizer%d_ips' % interface, word_offset=slot//self.n_interfaces))
    #        ant = self.fpga.read_uint('packetizer%d_ants' % interface, word_offset=slot//self.n_interfaces)
    #        header_chan = self.fpga.read_uint('packetizer%d_chans' % interface, word_offset=slot//self.n_interfaces)
    #        if dest_ip == "0.0.0.0":
    #            # Slot isn't going anywhere
    #            continue
    #        else:
    #            outputs += [{'chans':chans, 'interface':interface, 'dest_ip':dest_ip, 'ant':ant, 'header_chan':header_chan}]
    #            if header_chan != chans[0]:
    #                self.logger.warning("Header channel %d doesn't seem to match actual channel range, which starts at %d" % (header_chan, chans[0]))
    #    return outputs

    def _assign_chans(self, channel_range, start_index):
        """
        Reorder channels such that channel_range[i] takes index start_index+i

        Example usage:
            Move channels 0..15 to the middle of the band
                _assign_chans(range(16), 4096)
            Move channels 12,13,14,15,0,1,2,3 to the start of the band
                _assign_chans([12,13,14,15,0,1,2,3], 0)

        `channel_range` must be a multiple of 4 channels long, in contiguous blocks
        of 4 channels. Eg. [0 1 2 3, 12 13 14 15] is OK, but [0, 1, 2, 3, 14, 15, 16, 17] is not.
        `start_index` must be a multiple of 4.

        :param channel_range: Input channel order.
        :type channel_range: list of ints
        :param start_index:
        :type start_index: int
        :raises AssertionError: If above conditions on `channel_range` and `start_index` are not met.
        """
        assert len(channel_range) % 4 == 0
        assert start_index % 4 == 0
        self.logger.info("Reordering channels %s to start at index %d" % (channel_range, start_index))
        channel_range = [x//4 for x in channel_range[0::4]]
        channel_range_str = struct.pack('>%dH' % (len(channel_range)), *channel_range)
        start_index = start_index // 4
        # Write at offset 2*start_index, since each index is two bytes in memory
        write_offset = start_index * 2
        print(len(channel_range_str), write_offset)
        assert write_offset % 4 == 0, 'Attempted write incompatible with 32-bit word boundaries'
        self.fpga.write("chan_reorder_reorder3_map1", channel_range_str, offset=write_offset)
